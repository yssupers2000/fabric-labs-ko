---
lab:
    title: 'Use delta tables in Apache Spark'
    module: 'Work with Delta Lake tables in Microsoft Fabric'
---

# Apache Sparkì—ì„œ Delta Table ì‚¬ìš©

Microsoft Fabric Lakehouseì˜ Tableì€ ì˜¤í”ˆ ì†ŒìŠ¤ Delta Lake í˜•ì‹ ê¸°ë°˜ì…ë‹ˆë‹¤. Delta LakeëŠ” ë°°ì¹˜ ë° ìŠ¤íŠ¸ë¦¬ë° ë°ì´í„° ëª¨ë‘ì— ëŒ€í•œ ê´€ê³„í˜• ì‹œë§¨í‹± ì§€ì›ì„ ì¶”ê°€í•©ë‹ˆë‹¤. ì´ ì‹¤ìŠµì—ì„œëŠ” Delta Tableì„ ìƒì„±í•˜ê³  SQL ì¿¼ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë¥¼ íƒìƒ‰í•©ë‹ˆë‹¤.

ì´ ì‹¤ìŠµì€ ì™„ë£Œí•˜ëŠ” ë° ì•½ **45**ë¶„ ì •ë„ ì†Œìš”ë©ë‹ˆë‹¤.

> [!NOTE]
> ì´ ì‹¤ìŠµì„ ì™„ë£Œí•˜ë ¤ë©´ [Microsoft Fabric tenant](https://learn.microsoft.com/fabric/get-started/fabric-trial)ì— ëŒ€í•œ ì•¡ì„¸ìŠ¤ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.

## Workspace ìƒì„±

Fabricì—ì„œ ë°ì´í„°ë¥¼ ì‘ì—…í•˜ê¸° ì „ì—, Fabric Capacityê°€ í™œì„±í™”ëœ tenantì— Workspaceë¥¼ ìƒì„±í•˜ì„¸ìš”.

1. ë¸Œë¼ìš°ì €ì—ì„œ [Microsoft Fabric í™ˆ í˜ì´ì§€](https://app.fabric.microsoft.com/home?experience=fabric-developer) (`https://app.fabric.microsoft.com/home?experience=fabric-developer`)ë¡œ ì´ë™í•˜ì—¬ Fabric ìê²© ì¦ëª…ìœ¼ë¡œ ë¡œê·¸ì¸í•©ë‹ˆë‹¤.
2. ì™¼ìª½ì˜ ë©”ë‰´ ë°”ì—ì„œ **Workspaces** (ì•„ì´ì½˜ì€ &#128455;ì™€ ìœ ì‚¬í•©ë‹ˆë‹¤)ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.
3. ì›í•˜ëŠ” ì´ë¦„ìœ¼ë¡œ ìƒˆ Workspaceë¥¼ ìƒì„±í•˜ê³ , **Advanced** ì„¹ì…˜ì—ì„œ Fabric Capacityë¥¼ í¬í•¨í•˜ëŠ” ë¼ì´ì„ ìŠ¤ ëª¨ë“œ(*Trial*, *Premium*, ë˜ëŠ” *Fabric*)ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.
4. ìƒˆ Workspaceê°€ ì—´ë¦¬ë©´ ë¹„ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.

    ![Fabricì˜ ë¹ˆ Workspace ìŠ¤í¬ë¦°ìƒ·.](./Images/new-workspace.png)

## Lakehouse ìƒì„± ë° íŒŒì¼ ì—…ë¡œë“œ

ì´ì œ Workspaceë¥¼ ë§Œë“¤ì—ˆìœ¼ë‹ˆ, ë°ì´í„°ìš© Data Lakehouseë¥¼ ìƒì„±í•  ì°¨ë¡€ì…ë‹ˆë‹¤.

1. ì™¼ìª½ì˜ ë©”ë‰´ ë°”ì—ì„œ **Create**ë¥¼ ì„ íƒí•©ë‹ˆë‹¤. *New* í˜ì´ì§€ì˜ *Data Engineering* ì„¹ì…˜ì—ì„œ **Lakehouse**ë¥¼ ì„ íƒí•©ë‹ˆë‹¤. ì›í•˜ëŠ” ê³ ìœ í•œ ì´ë¦„ì„ ì§€ì •í•©ë‹ˆë‹¤. "Lakehouse schemas (Public Preview)" ì˜µì…˜ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.

    >**ì°¸ê³ **: **Create** ì˜µì…˜ì´ ì‚¬ì´ë“œë°”ì— ê³ ì •ë˜ì–´ ìˆì§€ ì•Šì€ ê²½ìš°, ë¨¼ì € ì¤„ì„í‘œ(**...**) ì˜µì…˜ì„ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤.

    1ë¶„ ì •ë„ í›„ì— ìƒˆ Lakehouseê°€ ìƒì„±ë©ë‹ˆë‹¤:

    ![ìƒˆ Lakehouse ìŠ¤í¬ë¦°ìƒ·.](./Images/new-lakehouse.png)

2. ìƒˆ Lakehouseë¥¼ í™•ì¸í•˜ê³ , ì™¼ìª½ì— ìˆëŠ” **Explorer** ì°½ì„ í†µí•´ Lakehouseì˜ Tableê³¼ íŒŒì¼ì„ íƒìƒ‰í•  ìˆ˜ ìˆìŒì— ìœ ì˜í•˜ì„¸ìš”:

ì´ì œ Lakehouseë¡œ ë°ì´í„°ë¥¼ ingest(ìˆ˜ì§‘)í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ ìœ„í•œ ì—¬ëŸ¬ ê°€ì§€ ë°©ë²•ì´ ìˆì§€ë§Œ, ì§€ê¸ˆì€ í…ìŠ¤íŠ¸ íŒŒì¼ì„ ë¡œì»¬ ì»´í“¨í„°(í•´ë‹¹í•˜ëŠ” ê²½ìš° ë© VM)ë¡œ ë‹¤ìš´ë¡œë“œí•œ ë‹¤ìŒ Lakehouseì— ì—…ë¡œë“œí•©ë‹ˆë‹¤.

1. `https://github.com/MicrosoftLearning/dp-data/raw/main/products.csv`ì—ì„œ [ë°ì´í„° íŒŒì¼](https://github.com/MicrosoftLearning/dp-data/raw/main/products.csv)ì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ *products.csv*ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
2. Lakehouseê°€ ì—´ë ¤ ìˆëŠ” ì›¹ ë¸Œë¼ìš°ì € íƒ­ìœ¼ë¡œ ëŒì•„ê°€ì„œ Explorer ì°½ì˜ **Files** í´ë” ì˜†ì— ìˆëŠ” â€¦ ë©”ë‰´ë¥¼ ì„ íƒí•©ë‹ˆë‹¤. *products*ë¼ëŠ” **New subfolder**ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
3. products í´ë”ì˜ â€¦ ë©”ë‰´ì—ì„œ ë¡œì»¬ ì»´í“¨í„°(í•´ë‹¹í•˜ëŠ” ê²½ìš° ë© VM)ì— ìˆëŠ” *products.csv* íŒŒì¼ì„ **ì—…ë¡œë“œ**í•©ë‹ˆë‹¤.
4. íŒŒì¼ì´ ì—…ë¡œë“œë˜ë©´ **products** í´ë”ë¥¼ ì„ íƒí•˜ì—¬ íŒŒì¼ì´ ì—…ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤. ë‹¤ìŒ ê·¸ë¦¼ê³¼ ê°™ìŠµë‹ˆë‹¤:

    ![Lakehouseì— ì—…ë¡œë“œëœ products.csv ìŠ¤í¬ë¦°ìƒ·.](Images/upload-products.png)

## DataFrameì—ì„œ ë°ì´í„° íƒìƒ‰

ì´ì œ ë°ì´í„° ì‘ì—…ì„ ìœ„í•´ Fabric Notebookì„ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. Notebookì€ ì½”ë“œë¥¼ ì‘ì„±í•˜ê³  ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” ëŒ€í™”í˜• í™˜ê²½ì„ ì œê³µí•©ë‹ˆë‹¤.

1. ì™¼ìª½ì˜ ë©”ë‰´ ë°”ì—ì„œ **Create**ë¥¼ ì„ íƒí•©ë‹ˆë‹¤. *New* í˜ì´ì§€ì˜ *Data Engineering* ì„¹ì…˜ì—ì„œ **Notebook**ì„ ì„ íƒí•©ë‹ˆë‹¤.

    **Notebook 1**ì´ë¼ëŠ” ìƒˆ Notebookì´ ìƒì„±ë˜ê³  ì—´ë¦½ë‹ˆë‹¤.

    ![ìƒˆ Notebook ìŠ¤í¬ë¦°ìƒ·.](./Images/new-notebook.png)

2. Fabricì€ ìƒì„±í•˜ëŠ” ê° Notebookì— Notebook 1, Notebook 2 ë“±ê³¼ ê°™ì€ ì´ë¦„ì„ í• ë‹¹í•©ë‹ˆë‹¤. ë©”ë‰´ì˜ **Home** íƒ­ ìœ„ì— ìˆëŠ” ì´ë¦„ íŒ¨ë„ì„ í´ë¦­í•˜ì—¬ ë” ì„¤ëª…ì ì¸ ì´ë¦„ìœ¼ë¡œ ë³€ê²½í•©ë‹ˆë‹¤.
3. ì²« ë²ˆì§¸ ì…€(í˜„ì¬ ì½”ë“œ ì…€)ì„ ì„ íƒí•œ ë‹¤ìŒ, ì˜¤ë¥¸ìª½ ìƒë‹¨ ë„êµ¬ ëª¨ìŒì—ì„œ **Mâ†“** ë²„íŠ¼ì„ ì‚¬ìš©í•˜ì—¬ Markdown ì…€ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë©´ ì…€ì— í¬í•¨ëœ í…ìŠ¤íŠ¸ê°€ ì„œì‹ ìˆëŠ” í…ìŠ¤íŠ¸ë¡œ í‘œì‹œë©ë‹ˆë‹¤.
4. ğŸ–‰ (í¸ì§‘) ë²„íŠ¼ì„ ì‚¬ìš©í•˜ì—¬ ì…€ì„ í¸ì§‘ ëª¨ë“œë¡œ ì „í™˜í•œ ë‹¤ìŒ, ì•„ë˜ì™€ ê°™ì´ Markdownì„ ìˆ˜ì •í•©ë‹ˆë‹¤.

    ```markdown
    # Delta Lake tables
    Use this notebook to explore Delta Lake functionality
    ```

5. ì…€ ì™¸ë¶€ì˜ Notebook ì•„ë¬´ ê³³ì´ë‚˜ í´ë¦­í•˜ì—¬ í¸ì§‘ì„ ì¤‘ì§€í•©ë‹ˆë‹¤.
6. **Explorer** ì°½ì—ì„œ **Add data items**ë¥¼ ì„ íƒí•œ ë‹¤ìŒ, **Existing data sources**ë¥¼ ì„ íƒí•©ë‹ˆë‹¤. ì´ì „ì— ìƒì„±í•œ Lakehouseì— ì—°ê²°í•©ë‹ˆë‹¤.
7. ìƒˆ ì½”ë“œ ì…€ì„ ì¶”ê°€í•˜ê³  ë‹¤ìŒ ì½”ë“œë¥¼ ì¶”ê°€í•˜ì—¬ ì •ì˜ëœ Schemaë¥¼ ì‚¬ìš©í•˜ì—¬ products ë°ì´í„°ë¥¼ DataFrameìœ¼ë¡œ ì½ìŠµë‹ˆë‹¤:

    ```python
   from pyspark.sql.types import StructType, IntegerType, StringType, DoubleType

   # define the schema
   schema = StructType() \
   .add("ProductID", IntegerType(), True) \
   .add("ProductName", StringType(), True) \
   .add("Category", StringType(), True) \
   .add("ListPrice", DoubleType(), True)

   df = spark.read.format("csv").option("header","true").schema(schema).load("Files/products/products.csv")
   # df now is a Spark DataFrame containing CSV data from "Files/products/products.csv".
   display(df)
    ```

> [!TIP]
> ì…°ë¸Œë¡  Â« ì•„ì´ì½˜ì„ ì‚¬ìš©í•˜ì—¬ Explorer ì°½ì„ ìˆ¨ê¸°ê±°ë‚˜ í‘œì‹œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ Notebook ë˜ëŠ” íŒŒì¼ì— ì§‘ì¤‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

8. ì…€ ì™¼ìª½ì— ìˆëŠ” **Run cell** (â–·) ë²„íŠ¼ì„ ì‚¬ìš©í•˜ì—¬ ì…€ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.

> [!NOTE]
> ì´ Notebookì—ì„œ ì½”ë“œë¥¼ ì²˜ìŒ ì‹¤í–‰í•˜ëŠ” ê²ƒì´ë¯€ë¡œ Spark sessionì„ ì‹œì‘í•´ì•¼ í•©ë‹ˆë‹¤. ì´ëŠ” ì²« ì‹¤í–‰ì— 1ë¶„ ì •ë„ ì†Œìš”ë  ìˆ˜ ìˆìŒì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ì´í›„ ì‹¤í–‰ì€ ë” ë¹¨ë¼ì§‘ë‹ˆë‹¤.

9. ì…€ ì½”ë“œê°€ ì™„ë£Œë˜ë©´, ë‹¤ìŒ ê·¸ë¦¼ê³¼ ìœ ì‚¬í•˜ê²Œ í‘œì‹œë˜ì–´ì•¼ í•˜ëŠ” ì…€ ì•„ë˜ì˜ ì¶œë ¥ì„ ê²€í† í•©ë‹ˆë‹¤:

    ![products.csv ë°ì´í„° ìŠ¤í¬ë¦°ìƒ·.](Images/products-schema.png)

## Delta Table ìƒì„±

*saveAsTable* ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ DataFrameì„ Delta Tableë¡œ ì €ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. Delta LakeëŠ” Managed Tableê³¼ External Table ìƒì„±ì„ ëª¨ë‘ ì§€ì›í•©ë‹ˆë‹¤:

*   **Managed** Delta Tableì€ Fabricì´ Schema Metadataì™€ ë°ì´í„° íŒŒì¼ ëª¨ë‘ë¥¼ ê´€ë¦¬í•˜ë¯€ë¡œ ë” ë†’ì€ ì„±ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
*   **External** Tableì€ Metadataê°€ Fabricì— ì˜í•´ ê´€ë¦¬ë˜ë©´ì„œ ë°ì´í„°ë¥¼ ì™¸ë¶€ì— ì €ì¥í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.

### Managed Table ìƒì„±

ë°ì´í„° íŒŒì¼ì€ **Tables** í´ë”ì— ìƒì„±ë©ë‹ˆë‹¤.

1. ì²« ë²ˆì§¸ ì½”ë“œ ì…€ì—ì„œ ë°˜í™˜ëœ ê²°ê³¼ ì•„ë˜ì—ì„œ + Code ì•„ì´ì½˜ì„ ì‚¬ìš©í•˜ì—¬ ìƒˆ ì½”ë“œ ì…€ì„ ì¶”ê°€í•©ë‹ˆë‹¤.

> [!TIP]
> + Code ì•„ì´ì½˜ì„ ë³´ë ¤ë©´ ë§ˆìš°ìŠ¤ë¥¼ í˜„ì¬ ì…€ì˜ ì¶œë ¥ ë°”ë¡œ ì•„ë˜ìª½ê³¼ ì™¼ìª½ìœ¼ë¡œ ì´ë™í•©ë‹ˆë‹¤. ë˜ëŠ” ë©”ë‰´ ë°”ì˜ Edit íƒ­ì—ì„œ **+ Add code cell**ì„ ì„ íƒí•©ë‹ˆë‹¤.

2. Managed Delta Tableì„ ìƒì„±í•˜ë ¤ë©´ ìƒˆ ì…€ì„ ì¶”ê°€í•˜ê³  ë‹¤ìŒ ì½”ë“œë¥¼ ì…ë ¥í•œ ë‹¤ìŒ ì…€ì„ ì‹¤í–‰í•©ë‹ˆë‹¤:

    ```python
   df.write.format("delta").saveAsTable("managed_products")
    ```

3. Explorer ì°½ì—ì„œ Tables í´ë”ë¥¼ **ìƒˆë¡œ ê³ ì¹¨**í•˜ê³  Tables ë…¸ë“œë¥¼ í™•ì¥í•˜ì—¬ **managed_products** Tableì´ ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.

> [!NOTE]
> íŒŒì¼ ì´ë¦„ ì˜†ì˜ ì‚¼ê°í˜• ì•„ì´ì½˜ì€ Delta Tableì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.

Managed Tableì˜ íŒŒì¼ì€ Lakehouseì˜ **Tables** í´ë”ì— ì €ì¥ë©ë‹ˆë‹¤. *managed_products*ë¼ëŠ” í´ë”ê°€ ìƒì„±ë˜ì–´ Tableì˜ Parquet íŒŒì¼ê³¼ delta_log í´ë”ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.

### External Table ìƒì„±

External Tableì„ ìƒì„±í•  ìˆ˜ë„ ìˆìœ¼ë©°, ì´ í…Œì´ë¸”ì€ Lakehouseê°€ ì•„ë‹Œ ë‹¤ë¥¸ ê³³ì— ì €ì¥ë  ìˆ˜ ìˆìœ¼ë©° Schema MetadataëŠ” Lakehouseì— ì €ì¥ë©ë‹ˆë‹¤.

1. Explorer ì°½ì˜ **Files** í´ë”ì— ëŒ€í•œ â€¦ ë©”ë‰´ì—ì„œ **Copy ABFS path**ë¥¼ ì„ íƒí•©ë‹ˆë‹¤. ABFS pathëŠ” Lakehouse Files í´ë”ì— ëŒ€í•œ ì „ì²´ ê²½ë¡œì…ë‹ˆë‹¤.

2. ìƒˆ ì½”ë“œ ì…€ì— ABFS pathë¥¼ ë¶™ì—¬ë„£ìŠµë‹ˆë‹¤. ë‹¤ìŒ ì½”ë“œë¥¼ ì¶”ê°€í•˜ê³ , ì˜ë¼ë‚´ê¸° ë° ë¶™ì—¬ë„£ê¸°ë¥¼ ì‚¬ìš©í•˜ì—¬ abfs_pathë¥¼ ì½”ë“œì˜ ì˜¬ë°”ë¥¸ ìœ„ì¹˜ì— ì‚½ì…í•©ë‹ˆë‹¤:

    ```python
   df.write.format("delta").saveAsTable("external_products", path="abfs_path/external_products")
    ```

3. ì „ì²´ ê²½ë¡œëŠ” ë‹¤ìŒê³¼ ìœ ì‚¬í•˜ê²Œ í‘œì‹œë˜ì–´ì•¼ í•©ë‹ˆë‹¤:

    ```python
   abfss://workspace@tenant-onelake.dfs.fabric.microsoft.com/lakehousename.Lakehouse/Files/external_products
    ```

4. ì…€ì„ **ì‹¤í–‰**í•˜ì—¬ DataFrameì„ Files/external_products í´ë”ì— External Tableë¡œ ì €ì¥í•©ë‹ˆë‹¤.

5. Explorer ì°½ì—ì„œ Tables í´ë”ë¥¼ **ìƒˆë¡œ ê³ ì¹¨**í•˜ê³  Tables ë…¸ë“œë¥¼ í™•ì¥í•˜ì—¬ external_products Tableì´ Schema Metadataë¥¼ í¬í•¨í•˜ì—¬ ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.

6. Explorer ì°½ì˜ Files í´ë”ì— ëŒ€í•œ â€¦ ë©”ë‰´ì—ì„œ **ìƒˆë¡œ ê³ ì¹¨**ì„ ì„ íƒí•©ë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ Files ë…¸ë“œë¥¼ í™•ì¥í•˜ì—¬ Tableì˜ ë°ì´í„° íŒŒì¼ì„ ìœ„í•œ external_products í´ë”ê°€ ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.

### Managed Tableê³¼ External Table ë¹„êµ

%%sql magic commandë¥¼ ì‚¬ìš©í•˜ì—¬ Managed Tableê³¼ External Table ê°„ì˜ ì°¨ì´ì ì„ íƒìƒ‰í•´ ë³´ê² ìŠµë‹ˆë‹¤.

1. ìƒˆ ì½”ë“œ ì…€ì—ì„œ ë‹¤ìŒ ì½”ë“œë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤:

    ```python
   %%sql
   DESCRIBE FORMATTED managed_products;
    ```

2. ê²°ê³¼ì—ì„œ Tableì˜ Location ì†ì„±ì„ í™•ì¸í•©ë‹ˆë‹¤. Data type ì—´ì˜ Location ê°’ì„ í´ë¦­í•˜ì—¬ ì „ì²´ ê²½ë¡œë¥¼ í™•ì¸í•©ë‹ˆë‹¤. OneLake ì €ì¥ ìœ„ì¹˜ê°€ /Tables/managed_productsë¡œ ëë‚˜ëŠ” ê²ƒì„ í™•ì¸í•˜ì„¸ìš”.

3. DESCRIBE ëª…ë ¹ì„ ìˆ˜ì •í•˜ì—¬ ë‹¤ìŒ ê·¸ë¦¼ê³¼ ê°™ì´ external_products Tableì˜ ì„¸ë¶€ ì •ë³´ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤:

    ```python
   %%sql
   DESCRIBE FORMATTED external_products;
    ```

4. ì…€ì„ ì‹¤í–‰í•˜ê³  ê²°ê³¼ì—ì„œ Tableì˜ Location ì†ì„±ì„ í™•ì¸í•©ë‹ˆë‹¤. Data type ì—´ì„ ë„“í˜€ ì „ì²´ ê²½ë¡œë¥¼ í™•ì¸í•˜ê³  OneLake ì €ì¥ ìœ„ì¹˜ê°€ /Files/external_productsë¡œ ëë‚˜ëŠ” ê²ƒì„ í™•ì¸í•˜ì„¸ìš”.

5. ìƒˆ ì½”ë“œ ì…€ì—ì„œ ë‹¤ìŒ ì½”ë“œë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤:

    ```python
   %%sql
   DROP TABLE managed_products;
   DROP TABLE external_products;
    ```

6. Explorer ì°½ì—ì„œ Tables í´ë”ë¥¼ **ìƒˆë¡œ ê³ ì¹¨**í•˜ì—¬ Tables ë…¸ë“œì— Tableì´ ë‚˜ì—´ë˜ì§€ ì•ŠëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
7. Explorer ì°½ì—ì„œ Files í´ë”ë¥¼ **ìƒˆë¡œ ê³ ì¹¨**í•˜ê³  external_products íŒŒì¼ì´ ì‚­ì œë˜ì§€ *ì•Šì•˜ëŠ”ì§€* í™•ì¸í•©ë‹ˆë‹¤. ì´ í´ë”ë¥¼ ì„ íƒí•˜ì—¬ Parquet ë°ì´í„° íŒŒì¼ê³¼ _delta_log í´ë”ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.

External Tableì˜ MetadataëŠ” ì‚­ì œë˜ì—ˆì§€ë§Œ, ë°ì´í„° íŒŒì¼ì€ ì‚­ì œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.

## SQLì„ ì‚¬ìš©í•˜ì—¬ Delta Table ìƒì„±

ì´ì œ %%sql magic commandë¥¼ ì‚¬ìš©í•˜ì—¬ Delta Tableì„ ìƒì„±í•©ë‹ˆë‹¤.

1. ë‹¤ë¥¸ ì½”ë“œ ì…€ì„ ì¶”ê°€í•˜ê³  ë‹¤ìŒ ì½”ë“œë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤:

    ```python
   %%sql
   CREATE TABLE products
   USING DELTA
   LOCATION 'Files/external_products';
    ```

2. Explorer ì°½ì˜ **Tables** í´ë”ì— ëŒ€í•œ â€¦ ë©”ë‰´ì—ì„œ **ìƒˆë¡œ ê³ ì¹¨**ì„ ì„ íƒí•©ë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ Tables ë…¸ë“œë¥¼ í™•ì¥í•˜ì—¬ *products*ë¼ëŠ” ìƒˆ Tableì´ ë‚˜ì—´ë˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤. ì´ì–´ì„œ Tableì„ í™•ì¥í•˜ì—¬ Schemaë¥¼ í™•ì¸í•©ë‹ˆë‹¤.
3. ë‹¤ë¥¸ ì½”ë“œ ì…€ì„ ì¶”ê°€í•˜ê³  ë‹¤ìŒ ì½”ë“œë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤:

    ```python
   %%sql
   SELECT * FROM products;
    ```

## Table ë²„ì „ ê´€ë¦¬ íƒìƒ‰

Delta Tableì˜ íŠ¸ëœì­ì…˜ ê¸°ë¡ì€ delta_log í´ë”ì˜ JSON íŒŒì¼ì— ì €ì¥ë©ë‹ˆë‹¤. ì´ íŠ¸ëœì­ì…˜ ë¡œê·¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° ë²„ì „ ê´€ë¦¬ë¥¼ ê´€ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

1. Notebookì— ìƒˆ ì½”ë“œ ì…€ì„ ì¶”ê°€í•˜ê³  ì‚°ì•… ìì „ê±° ê°€ê²©ì„ 10% ì¸í•˜í•˜ëŠ” ë‹¤ìŒ ì½”ë“œë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤:

    ```python
   %%sql
   UPDATE products
   SET ListPrice = ListPrice * 0.9
   WHERE Category = 'Mountain Bikes';
    ```

2. ë‹¤ë¥¸ ì½”ë“œ ì…€ì„ ì¶”ê°€í•˜ê³  ë‹¤ìŒ ì½”ë“œë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤:

    ```python
   %%sql
   DESCRIBE HISTORY products;
    ```

ê²°ê³¼ëŠ” Tableì— ê¸°ë¡ëœ íŠ¸ëœì­ì…˜ ê¸°ë¡ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

3. ë‹¤ë¥¸ ì½”ë“œ ì…€ì„ ì¶”ê°€í•˜ê³  ë‹¤ìŒ ì½”ë“œë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤:

    ```python
   delta_table_path = 'Files/external_products'
   # Get the current data
   current_data = spark.read.format("delta").load(delta_table_path)
   display(current_data)

   # Get the version 0 data
   original_data = spark.read.format("delta").option("versionAsOf", 0).load(delta_table_path)
   display(original_data)
    ```

ë‘ ê°œì˜ ê²°ê³¼ ì„¸íŠ¸ê°€ ë°˜í™˜ë©ë‹ˆë‹¤. í•˜ë‚˜ëŠ” ê°€ê²© ì¸í•˜ í›„ì˜ ë°ì´í„°ë¥¼ í¬í•¨í•˜ê³ , ë‹¤ë¥¸ í•˜ë‚˜ëŠ” ì›ë³¸ ë²„ì „ì˜ ë°ì´í„°ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.

## SQL ì¿¼ë¦¬ë¡œ Delta Table ë°ì´í„° ë¶„ì„

SQL magic commandë¥¼ ì‚¬ìš©í•˜ë©´ PySpark ëŒ€ì‹  SQL êµ¬ë¬¸ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” `SELECT` ë¬¸ì„ ì‚¬ìš©í•˜ì—¬ products Tableì—ì„œ ì„ì‹œ Viewë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

1. ìƒˆ ì½”ë“œ ì…€ì„ ì¶”ê°€í•˜ê³  ë‹¤ìŒ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ì—¬ ì„ì‹œ Viewë¥¼ ìƒì„±í•˜ê³  í‘œì‹œí•©ë‹ˆë‹¤:

    ```python
   %%sql
   -- Create a temporary view
   CREATE OR REPLACE TEMPORARY VIEW products_view
   AS
       SELECT Category, COUNT(*) AS NumProducts, MIN(ListPrice) AS MinPrice, MAX(ListPrice) AS MaxPrice, AVG(ListPrice) AS AvgPrice
       FROM products
       GROUP BY Category;

   SELECT *
   FROM products_view
   ORDER BY Category;
    ```

2. ìƒˆ ì½”ë“œ ì…€ì„ ì¶”ê°€í•˜ê³  ë‹¤ìŒ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ì—¬ ì œí’ˆ ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ìƒìœ„ 10ê°œ Categoryë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤:

    ```python
   %%sql
   SELECT Category, NumProducts
   FROM products_view
   ORDER BY NumProducts DESC
   LIMIT 10;
    ```

3. ë°ì´í„°ê°€ ë°˜í™˜ë˜ë©´ **+ New chart**ë¥¼ ì„ íƒí•˜ì—¬ ì œì•ˆëœ ì°¨íŠ¸ ì¤‘ í•˜ë‚˜ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.

    ![SQL SELECT ë¬¸ ë° ê²°ê³¼ ìŠ¤í¬ë¦°ìƒ·.](Images/sql-select.png)

ë˜ëŠ” PySparkë¥¼ ì‚¬ìš©í•˜ì—¬ SQL ì¿¼ë¦¬ë¥¼ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

1. ìƒˆ ì½”ë“œ ì…€ì„ ì¶”ê°€í•˜ê³  ë‹¤ìŒ ì½”ë“œë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤:

    ```python
   from pyspark.sql.functions import col, desc

   df_products = spark.sql("SELECT Category, MinPrice, MaxPrice, AvgPrice FROM products_view").orderBy(col("AvgPrice").desc())
   display(df_products.limit(6))
    ```

## ìŠ¤íŠ¸ë¦¬ë° ë°ì´í„°ì— Delta Table ì‚¬ìš©

Delta LakeëŠ” ìŠ¤íŠ¸ë¦¬ë° ë°ì´í„°ë¥¼ ì§€ì›í•©ë‹ˆë‹¤. Delta Tableì€ Spark Structured Streaming APIë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒì„±ëœ ë°ì´í„° ìŠ¤íŠ¸ë¦¼ì˜ Sink ë˜ëŠ” Sourceê°€ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ì˜ˆì‹œì—ì„œëŠ” ì‹œë®¬ë ˆì´ì…˜ëœ IoT(Internet of Things) ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ì¼ë¶€ ìŠ¤íŠ¸ë¦¬ë° ë°ì´í„°ì˜ Sinkë¡œ Delta Tableì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

1. ìƒˆ ì½”ë“œ ì…€ì„ ì¶”ê°€í•˜ê³  ë‹¤ìŒ ì½”ë“œë¥¼ ì¶”ê°€í•˜ì—¬ ì‹¤í–‰í•©ë‹ˆë‹¤:

    ```python
    from notebookutils import mssparkutils
    from pyspark.sql.types import *
    from pyspark.sql.functions import *

    # Create a folder
    inputPath = 'Files/data/'
    mssparkutils.fs.mkdirs(inputPath)

    # Create a stream that reads data from the folder, using a JSON schema
    jsonSchema = StructType([
    StructField("device", StringType(), False),
    StructField("status", StringType(), False)
    ])
    iotstream = spark.readStream.schema(jsonSchema).option("maxFilesPerTrigger", 1).json(inputPath)

    # Write some event data to the folder
    device_data = '''{"device":"Dev1","status":"ok"}
    {"device":"Dev1","status":"ok"}
    {"device":"Dev1","status":"ok"}
    {"device":"Dev2","status":"error"}
    {"device":"Dev1","status":"ok"}
    {"device":"Dev1","status":"error"}
    {"device":"Dev2","status":"ok"}
    {"device":"Dev2","status":"error"}
    {"device":"Dev1","status":"ok"}'''

    mssparkutils.fs.put(inputPath + "data.txt", device_data, True)

    print("Source stream created...")
    ```

*Source stream createdâ€¦* ë©”ì‹œì§€ê°€ í‘œì‹œë˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤. ë°©ê¸ˆ ì‹¤í–‰í•œ ì½”ë“œëŠ” ê°€ìƒì˜ IoT ë””ë°”ì´ìŠ¤ì—ì„œ ì½ì€ ë°ì´í„°ë¥¼ ë‚˜íƒ€ë‚´ëŠ”, ì¼ë¶€ ë°ì´í„°ê°€ ì €ì¥ëœ í´ë”ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë° ë°ì´í„° Sourceë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤.

2. ìƒˆ ì½”ë“œ ì…€ì— ë‹¤ìŒ ì½”ë“œë¥¼ ì¶”ê°€í•˜ê³  ì‹¤í–‰í•©ë‹ˆë‹¤:

    ```python
   # Write the stream to a delta table
   delta_stream_table_path = 'Tables/iotdevicedata'
   checkpointpath = 'Files/delta/checkpoint'
   deltastream = iotstream.writeStream.format("delta").option("checkpointLocation", checkpointpath).start(delta_stream_table_path)
   print("Streaming to delta sink...")
    ```

ì´ ì½”ë“œëŠ” ìŠ¤íŠ¸ë¦¬ë° ë””ë°”ì´ìŠ¤ ë°ì´í„°ë¥¼ Delta í˜•ì‹ìœ¼ë¡œ iotdevicedataë¼ëŠ” í´ë”ì— ì”ë‹ˆë‹¤. Tables í´ë”ì— ìˆëŠ” í´ë” ìœ„ì¹˜ì˜ ê²½ë¡œ ë•Œë¬¸ì— í•´ë‹¹ í´ë”ì— Tableì´ ìë™ìœ¼ë¡œ ìƒì„±ë©ë‹ˆë‹¤.

3. ìƒˆ ì½”ë“œ ì…€ì— ë‹¤ìŒ ì½”ë“œë¥¼ ì¶”ê°€í•˜ê³  ì‹¤í–‰í•©ë‹ˆë‹¤:

    ```python
   %%sql
   SELECT * FROM IotDeviceData;
    ```

ì´ ì½”ë“œëŠ” ìŠ¤íŠ¸ë¦¬ë° Sourceì—ì„œ ê°€ì ¸ì˜¨ ë””ë°”ì´ìŠ¤ ë°ì´í„°ë¥¼ í¬í•¨í•˜ëŠ” IotDeviceData Tableì„ ì¿¼ë¦¬í•©ë‹ˆë‹¤.

4. ìƒˆ ì½”ë“œ ì…€ì— ë‹¤ìŒ ì½”ë“œë¥¼ ì¶”ê°€í•˜ê³  ì‹¤í–‰í•©ë‹ˆë‹¤:

    ```python
   # Add more data to the source stream
   more_data = '''{"device":"Dev1","status":"ok"}
   {"device":"Dev1","status":"ok"}
   {"device":"Dev1","status":"ok"}
   {"device":"Dev1","status":"ok"}
   {"device":"Dev1","status":"error"}
   {"device":"Dev2","status":"error"}
   {"device":"Dev1","status":"ok"}'''

   mssparkutils.fs.put(inputPath + "more-data.txt", more_data, True)
    ```

ì´ ì½”ë“œëŠ” ë” ë§ì€ ê°€ìƒì˜ ë””ë°”ì´ìŠ¤ ë°ì´í„°ë¥¼ ìŠ¤íŠ¸ë¦¬ë° Sourceì— ì”ë‹ˆë‹¤.

5. ë‹¤ìŒ ì½”ë“œê°€ í¬í•¨ëœ ì…€ì„ ë‹¤ì‹œ ì‹¤í–‰í•©ë‹ˆë‹¤:

    ```python
   %%sql
   SELECT * FROM IotDeviceData;
    ```

ì´ ì½”ë“œëŠ” IotDeviceData Tableì„ ë‹¤ì‹œ ì¿¼ë¦¬í•©ë‹ˆë‹¤. ì´ í…Œì´ë¸”ì—ëŠ” ì´ì œ ìŠ¤íŠ¸ë¦¬ë° Sourceì— ì¶”ê°€ëœ ì¶”ê°€ ë°ì´í„°ê°€ í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.

6. ìƒˆ ì½”ë“œ ì…€ì— ìŠ¤íŠ¸ë¦¼ì„ ì¤‘ì§€í•˜ëŠ” ì½”ë“œë¥¼ ì¶”ê°€í•˜ê³  ì…€ì„ ì‹¤í–‰í•©ë‹ˆë‹¤:

    ```python
   deltastream.stop()
    ```

## ë¦¬ì†ŒìŠ¤ ì •ë¦¬

ì´ ì‹¤ìŠµì—ì„œëŠ” Microsoft Fabricì—ì„œ Delta Tableì„ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì„ ë°°ì› ìŠµë‹ˆë‹¤.

Lakehouse íƒìƒ‰ì„ ë§ˆì³¤ë‹¤ë©´, ì´ ì‹¤ìŠµì„ ìœ„í•´ ìƒì„±í•œ Workspaceë¥¼ ì‚­ì œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

1. ì™¼ìª½ ë°”ì—ì„œ Workspace ì•„ì´ì½˜ì„ ì„ íƒí•˜ì—¬ í¬í•¨ëœ ëª¨ë“  í•­ëª©ì„ í™•ì¸í•©ë‹ˆë‹¤.
2. ë„êµ¬ ëª¨ìŒì˜ â€¦ ë©”ë‰´ì—ì„œ **Workspace settings**ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.
3. General ì„¹ì…˜ì—ì„œ **Remove this workspace**ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.
